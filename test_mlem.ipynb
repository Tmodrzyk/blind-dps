{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from guided_diffusion.blind_condition_methods import get_conditioning_method\n",
    "from guided_diffusion.measurements import get_operator, get_noise\n",
    "\n",
    "# Here replaces the regular unet by our trained unet\n",
    "# from guided_diffusion.unet import create_model\n",
    "import guided_diffusion.diffusion_model_unet \n",
    "import guided_diffusion.unet\n",
    "\n",
    "from guided_diffusion.gaussian_diffusion import create_sampler\n",
    "from data.dataloader import get_dataset, get_dataloader\n",
    "from motionblur.motionblur import Kernel\n",
    "from util.img_utils import Blurkernel, clear_color\n",
    "from util.logger import get_logger\n",
    "from skimage.restoration import richardson_lucy, wiener, unsupervised_wiener\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import convolve\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "device = 'cuda'\n",
    "    \n",
    "name = 'ffhq'\n",
    "root = '/home/modrzyk/code/data/EUSIPCO_2024/label/'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                ])\n",
    "dataset = get_dataset(name=name, root=root, transforms=transform)\n",
    "loader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)\n",
    "\n",
    "# set seed for reproduce\n",
    "# set seed for reproduce\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True  # if using CUDA\n",
    "\n",
    "\n",
    "\n",
    "def wiener_deconv(x_0_hat, steps, **kwargs):\n",
    "    img = x_0_hat['img'].numpy().astype(np.float32)\n",
    "    kernel = x_0_hat['kernel'].numpy().astype(np.float32)\n",
    "    \n",
    "    deconv_img = wiener(image=img, balance=1.0, psf=kernel, clip=False)\n",
    "    # deconv_img, _ = unsupervised_wiener(image=img.numpy(), psf=kernel.numpy(), clip=False)\n",
    "    \n",
    "    x_0_hat['img'] = torch.from_numpy(deconv_img).to(device)\n",
    "    \n",
    "    return x_0_hat\n",
    "\n",
    "def richardson_lucy_blind(image, psf, original, num_iter=50):    \n",
    "    im_deconv = original.copy()    # init output\n",
    "    for i in range(num_iter):\n",
    "        psf_mirror = np.flip(psf)\n",
    "        conv = fftconvolve(im_deconv, psf, mode='same')\n",
    "        relative_blur = image / conv\n",
    "        im_deconv *= fftconvolve(relative_blur, psf_mirror, mode='same')\n",
    "        im_deconv_mirror = np.flip(im_deconv)\n",
    "        psf *= fftconvolve(relative_blur, im_deconv_mirror, mode='same')    \n",
    "    return im_deconv, psf\n",
    "\n",
    "def blind_mlem(x_0_hat, steps, clip, filter_epsilon, **kwargs):\n",
    "    img = x_0_hat['img'].numpy()\n",
    "    psf = x_0_hat['kernel'].numpy()\n",
    "    \n",
    "    im_deconv, psf_deconv = richardson_lucy_blind(img, psf, img, num_iter=steps)\n",
    "    x_0_hat['img'] = torch.from_numpy(im_deconv).to(device)\n",
    "    x_0_hat['kernel'] = torch.from_numpy(psf_deconv).to(device)\n",
    "    \n",
    "    return x_0_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def mlem(observation, x_0_hat, steps, clip, filter_epsilon, **kwargs):\n",
    "    img = x_0_hat['img']\n",
    "    kernel = x_0_hat['kernel']\n",
    "    \n",
    "    image = observation.cpu().numpy().astype(np.float32, copy=True)\n",
    "    psf = kernel.cpu().numpy().astype(np.float32, copy=False)\n",
    "    # im_deconv = np.full(image.shape, 0.5, dtype=np.float32)\n",
    "    im_deconv = img.cpu().numpy().astype(np.float32, copy=True)\n",
    "    psf_mirror = np.flip(psf)\n",
    "\n",
    "    # Small regularization parameter used to avoid 0 divisions\n",
    "    eps = 1e-6\n",
    "\n",
    "    for _ in range(steps):\n",
    "        conv = convolve(im_deconv, psf, mode='same', method='fft') + eps\n",
    "        if filter_epsilon:\n",
    "            relative_blur = np.where(conv < filter_epsilon, 0, image / conv)\n",
    "        else:\n",
    "            relative_blur = image / conv\n",
    "        im_deconv *= convolve(relative_blur, psf_mirror, mode='same', method='fft')\n",
    "\n",
    "    if clip:\n",
    "        im_deconv[im_deconv > 1] = 1\n",
    "        im_deconv[im_deconv < -1] = -1\n",
    "\n",
    "    x_0_hat['img'] = torch.from_numpy(im_deconv).to(device)\n",
    "    \n",
    "    return x_0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "def mlem_gpu(observation, x_0_hat, steps, clip, filter_epsilon, device):\n",
    "    with torch.no_grad():\n",
    "        img = x_0_hat['img']\n",
    "        kernel = x_0_hat['kernel'].repeat(1,3,1,1)\n",
    "        # kernel = x_0_hat['kernel']\n",
    "        \n",
    "        image = observation.to(torch.float32).clone().to(device)\n",
    "        psf = kernel.to(torch.float32).clone().to(device)\n",
    "        im_deconv = img.to(torch.float32).clone().to(device)\n",
    "        psf_mirror = torch.flip(psf, dims=[0, 1])\n",
    "\n",
    "        # Small regularization parameter used to avoid 0 divisions\n",
    "        eps = 1e-12\n",
    "        pad = (psf.size(2) // 2, psf.size(2) // 2, psf.size(3) // 2, psf.size(3) // 2)\n",
    "        for _ in range(steps):\n",
    "            conv = F.conv2d(F.pad(im_deconv, pad, mode='replicate'), psf) + eps\n",
    "            if filter_epsilon:\n",
    "                relative_blur = torch.where(conv < filter_epsilon, torch.tensor(0.0, device=device), image / conv)\n",
    "            else:\n",
    "                relative_blur = image / conv\n",
    "            im_deconv *= F.conv2d(F.pad(relative_blur, pad, mode='replicate'), psf_mirror)\n",
    "\n",
    "            im_deconv = torch.from_numpy(denoise_tv_chambolle(im_deconv.cpu().numpy(), weight=0.005, max_num_iter=50, channel_axis=1)).to(device)\n",
    "            \n",
    "        if clip:\n",
    "            im_deconv = torch.clamp(im_deconv, -1, 1)\n",
    "\n",
    "        x_0_hat['img'] = im_deconv.to(device)\n",
    "    \n",
    "    return x_0_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:16<25:03,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "kernel_size = 61\n",
    "kernel_std = 3.0\n",
    "noise_level = 0.05\n",
    "\n",
    "operator = get_operator(name='gaussian_blur', kernel_size=kernel_size, intensity=kernel_std, device=device)\n",
    "noiser = get_noise(name='gaussian', sigma=noise_level)\n",
    "\n",
    "psnr_tab = []\n",
    "\n",
    "# Do Inference\n",
    "for i, ref_img in enumerate(tqdm(loader)):\n",
    "    if(i > 10):\n",
    "        break   \n",
    "    conv = Blurkernel('gaussian', kernel_size=kernel_size, std=kernel_std, device=device)\n",
    "    kernel = conv.get_kernel().type(torch.float32)\n",
    "    kernel = kernel.to(device).view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    ref_img = ref_img.to(device)\n",
    "    y_conv = operator.forward(ref_img)\n",
    "    y = noiser(y_conv)\n",
    "\n",
    "    y_mlem = y.clone()\n",
    "    y_mlem = torch.clamp(y_mlem, min=0)\n",
    "    \n",
    "    # Call mlem\n",
    "    x_0_hat={'img': y_mlem, 'kernel': kernel}\n",
    "    \n",
    "    psnr_values = []\n",
    "\n",
    "    def mlem_gpu(observation, x_0_hat, steps, clip, filter_epsilon, device):\n",
    "        with torch.no_grad():\n",
    "            img = x_0_hat['img']\n",
    "            kernel = x_0_hat['kernel'].repeat(1,3,1,1)\n",
    "            # kernel = x_0_hat['kernel']\n",
    "            \n",
    "            psnr_values = []\n",
    "\n",
    "            image = observation.to(torch.float32).clone().to(device)\n",
    "            psf = kernel.to(torch.float32).clone().to(device)\n",
    "            im_deconv = img.to(torch.float32).clone().to(device)\n",
    "            psf_mirror = torch.flip(psf, dims=[0, 1])\n",
    "\n",
    "            # Small regularization parameter used to avoid 0 divisions\n",
    "            eps = 1e-12\n",
    "            pad = (psf.size(2) // 2, psf.size(2) // 2, psf.size(3) // 2, psf.size(3) // 2)\n",
    "            for _ in range(steps):\n",
    "                conv = F.conv2d(F.pad(im_deconv, pad, mode='replicate'), psf) + eps\n",
    "                if filter_epsilon:\n",
    "                    relative_blur = torch.where(conv < filter_epsilon, torch.tensor(0.0, device=device), image / conv)\n",
    "                else:\n",
    "                    relative_blur = image / conv\n",
    "                im_deconv *= F.conv2d(F.pad(relative_blur, pad, mode='replicate'), psf_mirror)\n",
    "\n",
    "                im_deconv = torch.from_numpy(denoise_tv_chambolle(im_deconv.cpu().numpy(), weight=0.005, max_num_iter=50, channel_axis=1)).to(device)\n",
    "                \n",
    "                psnr_values.append(peak_signal_noise_ratio(ref_img.cpu().numpy(), torch.clamp(im_deconv, -1, 1).cpu().numpy()))\n",
    "            if clip:\n",
    "                im_deconv = torch.clamp(im_deconv, -1, 1)\n",
    "\n",
    "            x_0_hat['img'] = im_deconv.to(device)\n",
    "        \n",
    "        return x_0_hat, psnr_values\n",
    "\n",
    "    x_0_hat, psnr_values = mlem_gpu(y_mlem, x_0_hat, steps=40, clip=False, filter_epsilon=1e-15, device=device)\n",
    "\n",
    "    psnr_tab.append(psnr_values)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 27.47198872407659\n",
      "15 26.85524340129515\n",
      "31 28.883712080068587\n",
      "38 26.70252826697649\n",
      "34 22.608825886459876\n",
      "33 26.725120197067067\n",
      "25 27.13388440854719\n",
      "18 25.574857032982937\n",
      "24 26.73496557394038\n",
      "29 26.727218514995513\n",
      "20 23.116434288088485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.90909090909091"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_indices = [np.argmax(arr) for arr in psnr_tab]\n",
    "\n",
    "for i, k in zip(min_indices, range(len(min_indices))):\n",
    "    print(i, psnr_tab[k][i]) \n",
    "    \n",
    "np.mean(min_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:48<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "kernel_size = 61\n",
    "kernel_std = 3.0\n",
    "noise_level = 0.05\n",
    "\n",
    "operator = get_operator(name='gaussian_blur', kernel_size=kernel_size, intensity=kernel_std, device=device)\n",
    "noiser = get_noise(name='gaussian', sigma=noise_level)\n",
    "\n",
    "psnr_tab = []\n",
    "\n",
    "# Do Inference\n",
    "for i, ref_img in enumerate(tqdm(loader)):\n",
    "    if(i > 468):\n",
    "        conv = Blurkernel('gaussian', kernel_size=kernel_size, std=kernel_std, device=device)\n",
    "        kernel = conv.get_kernel().type(torch.float32)\n",
    "        kernel = kernel.to(device).view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "        ref_img = ref_img.to(device)\n",
    "        y_conv = operator.forward(ref_img)\n",
    "        y = noiser(y_conv)\n",
    "\n",
    "        y_mlem = y.clone()\n",
    "        y_mlem = torch.clamp(y_mlem, min=0)\n",
    "        \n",
    "        # Call mlem\n",
    "        x_0_hat={'img': y_mlem, 'kernel': kernel}\n",
    "        \n",
    "        psnr_values = []\n",
    "\n",
    "        x_0_hat = mlem_gpu(y_mlem, x_0_hat, steps=25, clip=False, filter_epsilon=1e-15, device=device)\n",
    "        psnr = peak_signal_noise_ratio(ref_img.cpu().numpy(), x_0_hat['img'].cpu().numpy())\n",
    "        psnr_values.append(psnr)\n",
    "\n",
    "        psnr_values = np.array(psnr_values)\n",
    "        \n",
    "        \n",
    "        # Specify the output directory\n",
    "        output_dir = './results/ffhq/richardson-lucy/'\n",
    "        label_dir = os.path.join(output_dir, 'label')\n",
    "        input_dir = os.path.join(output_dir, 'input')\n",
    "        recon_dir = os.path.join(output_dir, 'recon')\n",
    "        \n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        os.makedirs(input_dir, exist_ok=True)\n",
    "        os.makedirs(recon_dir, exist_ok=True)\n",
    "\n",
    "        # Save the images\n",
    "        output_path_original = os.path.join(output_dir, 'label', f'{str(i).zfill(5)}.png')\n",
    "        output_path_measurement = os.path.join(output_dir, 'input', f'{str(i).zfill(5)}.png')\n",
    "        output_path_mlem = os.path.join(output_dir, 'recon', f'{str(i).zfill(5)}.png')\n",
    "\n",
    "        # Save the original image\n",
    "        plt.imsave(output_path_original, clear_color(ref_img))\n",
    "\n",
    "        # Save the measurement image\n",
    "        plt.imsave(output_path_measurement, clear_color(y_mlem))\n",
    "\n",
    "        # Save the MLEM image\n",
    "        plt.imsave(output_path_mlem, clear_color(x_0_hat['img']))\n",
    "\n",
    "        psnr_tab.append(psnr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([27.38016392, 27.06987285, 26.47366818, 25.78959156, 25.04268333,\n",
       "        24.25774465, 23.43894457, 22.57212148]),\n",
       " array([26.66908039, 26.19404774, 25.19876411, 23.87090406, 22.50583346,\n",
       "        21.26535303, 20.1159095 , 19.02529859]),\n",
       " array([28.6015395 , 28.67292075, 28.4014288 , 28.05017924, 27.64035424,\n",
       "        27.19399464, 26.69667925, 26.1056366 ]),\n",
       " array([26.33872798, 26.52201741, 26.26174517, 25.87703418, 25.38428416,\n",
       "        24.79060871, 24.12216647, 23.36355165]),\n",
       " array([22.32424186, 22.35960646, 22.16874455, 21.9377999 , 21.67544075,\n",
       "        21.33137803, 20.89107093, 20.35884114])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "min_indices = [np.argmax(arr) for arr in psnr_tab]\n",
    "print(min_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlindDPS_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
