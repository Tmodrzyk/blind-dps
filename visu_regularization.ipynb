{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from guided_diffusion.blind_condition_methods import get_conditioning_method\n",
    "from guided_diffusion.measurements import get_operator, get_noise\n",
    "\n",
    "# Here replaces the regular unet by our trained unet\n",
    "# from guided_diffusion.unet import create_model\n",
    "import guided_diffusion.diffusion_model_unet \n",
    "import guided_diffusion.unet\n",
    "\n",
    "from guided_diffusion.gaussian_diffusion import create_sampler\n",
    "from data.dataloader import get_dataset, get_dataloader\n",
    "from motionblur.motionblur import Kernel\n",
    "from util.img_utils import Blurkernel, clear_color\n",
    "from util.logger import get_logger\n",
    "from skimage.restoration import richardson_lucy, wiener, unsupervised_wiener\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import convolve\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "device = 'cuda'\n",
    "    \n",
    "name = 'ffhq'\n",
    "root = '/home/modrzyk/code/data/EUSIPCO_2024/label/'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                ])\n",
    "dataset = get_dataset(name=name, root=root, transforms=transform)\n",
    "loader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)\n",
    "\n",
    "# set seed for reproduce\n",
    "# set seed for reproduce\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True  # if using CUDA\n",
    "\n",
    "def mlem_gpu(observation, x_0_hat, steps, clip, filter_epsilon, device, reg, lam=0.005):\n",
    "    with torch.no_grad():\n",
    "        kernel = x_0_hat['kernel'].repeat(1, 3, 1, 1)\n",
    "        \n",
    "        image = observation.to(torch.float32).clone().to(device)\n",
    "        psf = kernel.to(torch.float32).clone().to(device)\n",
    "        im_deconv = x_0_hat['img'].to(torch.float32).clone().to(device)\n",
    "        psf_mirror = torch.flip(psf, dims=[2, 3])  # Flipping should be on the last two dimensions for 4D tensor\n",
    "\n",
    "        # Define the Laplacian kernel for gradient L2 regularization\n",
    "        laplacian_kernel = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], device=device, dtype=torch.float32)\n",
    "        laplacian_kernel = laplacian_kernel.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 3, 3] to match convolution requirements\n",
    "        laplacian_kernel = laplacian_kernel.repeat(1, 3, 1, 1)  \n",
    "        eps = 1e-12\n",
    "        pad = (psf.size(2) // 2, psf.size(2) // 2, psf.size(3) // 2, psf.size(3) // 2)\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            conv = F.conv2d(F.pad(im_deconv, pad, mode='replicate'), psf) + eps\n",
    "            if filter_epsilon:\n",
    "                relative_blur = torch.where(conv < filter_epsilon, torch.tensor(0.0, device=device), image / conv)\n",
    "            else:\n",
    "                relative_blur = image / conv\n",
    "            im_deconv *= F.conv2d(F.pad(relative_blur, pad, mode='replicate'), psf_mirror)\n",
    "\n",
    "            if reg == \"tv\":\n",
    "                im_deconv = torch.from_numpy(denoise_tv_chambolle(im_deconv.cpu().numpy(), weight=0.005, max_num_iter=50, channel_axis=1)).to(device)\n",
    "            \n",
    "            elif reg == \"l1\":\n",
    "                im_deconv -= lam * torch.sign(im_deconv)\n",
    "                \n",
    "            elif reg == \"l2\":\n",
    "                im_deconv -= lam * im_deconv\n",
    "\n",
    "            elif reg == \"grad_l2\":\n",
    "                # Convolve with the Laplacian kernel and update\n",
    "                laplacian = F.conv2d(im_deconv, laplacian_kernel, padding=1)\n",
    "                im_deconv -= lam * laplacian\n",
    "            \n",
    "            elif reg == \"h1\":\n",
    "                # L2 regularization on image values\n",
    "                im_deconv -= lam * im_deconv\n",
    "\n",
    "                # L2 regularization on the image gradient (smoothness)\n",
    "                laplacian = F.conv2d(im_deconv, laplacian_kernel, padding=1)\n",
    "                im_deconv -= lam * laplacian\n",
    "                \n",
    "        if clip:\n",
    "            im_deconv = torch.clamp(im_deconv, -1, 1)\n",
    "\n",
    "        return im_deconv.to(device)\n",
    "    \n",
    "    \n",
    "def gd(observation, x_0_hat, steps, learning_rate, device, reg_type=None, lambda_reg=0.001):\n",
    "    psf = x_0_hat['kernel'].repeat(1, 3, 1, 1)\n",
    "    x_hat = observation.clone().to(device)\n",
    "    psf = psf.to(device)\n",
    "    psf /= psf.sum()\n",
    "    psf_flipped = torch.flip(psf, [2, 3])\n",
    "    \n",
    "    laplacian_kernel = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
    "    laplacian_kernel = laplacian_kernel.repeat(1, 3, 1, 1)\n",
    "    for step in range(steps):\n",
    "        convolved = F.conv2d(x_hat, psf, padding='same')\n",
    "        gradient = 2 * (convolved - observation)\n",
    "\n",
    "        if reg_type == \"L2\":\n",
    "            gradient += 2 * lambda_reg * x_hat\n",
    "        elif reg_type == \"L1\":\n",
    "            gradient += lambda_reg * torch.sign(x_hat)\n",
    "        elif reg_type == \"H1\":\n",
    "            # Add L2 regularization\n",
    "            gradient += 2 * lambda_reg * x_hat\n",
    "            # Approximate gradient's L2 norm using Laplacian for smoothness\n",
    "            laplacian_x_hat = F.conv2d(x_hat, laplacian_kernel, padding=1)\n",
    "            gradient += 2 * lambda_reg * laplacian_x_hat\n",
    "\n",
    "        x_hat -= learning_rate * F.conv2d(gradient, psf_flipped, padding='same')\n",
    "    \n",
    "    return x_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 178.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "kernel_size = 61\n",
    "kernel_std = 3.0\n",
    "noise_level = 0.05\n",
    "\n",
    "operator = get_operator(name='gaussian_blur', kernel_size=kernel_size, intensity=kernel_std, device=device)\n",
    "noiser = get_noise(name='gaussian', sigma=noise_level)\n",
    "\n",
    "psnr_tab = []\n",
    "\n",
    "# Do Inference\n",
    "for i, ref_img in enumerate(tqdm(loader)):\n",
    "    if(i==1):\n",
    "        conv = Blurkernel('gaussian', kernel_size=kernel_size, std=kernel_std, device=device)\n",
    "        kernel = conv.get_kernel().type(torch.float32)\n",
    "        kernel = kernel.to(device).view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "        ref_img = ref_img.to(device)\n",
    "        y_conv = operator.forward(ref_img)\n",
    "        y = noiser(y_conv)\n",
    "\n",
    "        y_mlem = y.clone()\n",
    "        y_mlem = torch.clamp(y_mlem, min=0)\n",
    "        \n",
    "        # Call mlem\n",
    "        x_0_hat={'img': y_mlem, 'kernel': kernel}\n",
    "        \n",
    "        x_0_rl = mlem_gpu(y_mlem, x_0_hat, steps=40, clip=False, filter_epsilon=0, device=device, reg=None, lam = 0)\n",
    "        x_0_rl_tv = mlem_gpu(y_mlem, x_0_hat, steps=40, clip=False, filter_epsilon=1e-15, device=device, reg=\"tv\", lam = 0.005)\n",
    "        \n",
    "        # x_0_gd = gd(y_mlem, x_0_hat, steps=40, learning_rate=1.0, device=device, reg_type=None, lambda_reg = 0)\n",
    "        # x_0_gd_l1 = gd(y_mlem, x_0_hat, steps=40, learning_rate=1.0, device=device, reg_type=\"L1\", lambda_reg = 0.03)\n",
    "        # x_0_gd_l2 = gd(y_mlem, x_0_hat, steps=40, learning_rate=1.0, device=device, reg_type=\"L2\", lambda_reg = 0.03)\n",
    "        # x_0_gd_h1 = gd(y_mlem, x_0_hat, steps=40, learning_rate=1.0, device=device, reg_type=\"H1\", lambda_reg = 0.04)\n",
    "    \n",
    "        plt.imsave('results/rl.png', torch.clamp(x_0_rl, 0, 1).squeeze().detach().cpu().numpy().transpose(1, 2, 0))\n",
    "        plt.imsave('results/rl_tv.png', torch.clamp(x_0_rl_tv, 0, 1).squeeze().detach().cpu().numpy().transpose(1, 2, 0))\n",
    "        plt.imsave('results/y.png', torch.clamp(y, 0, 1).squeeze().detach().cpu().numpy().transpose(1, 2, 0))\n",
    "        plt.imsave('results/ref_img.png', torch.clamp(ref_img, 0, 1).squeeze().detach().cpu().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlindDPS_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
